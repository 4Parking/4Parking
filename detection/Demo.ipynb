{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "elementary-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "silent-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_overlap_parking_area(p, d):\n",
    "    '''\n",
    "    Calculating ratio of area of parking spot, \n",
    "    which is overlapped by detected object\n",
    "    \n",
    "    p: (xp1, yp1, xp2, yp2) - tuple of left upper coordinate and\n",
    "    bottom right coordinate of parking spot\n",
    "    d: (xd1, yd1, xd2, yd2) - tuple of left upper coordinate and\n",
    "    bottom right coordinate of detected object\n",
    "    '''\n",
    "    xp1, yp1, xp2, yp2 = p\n",
    "    xd1, yd1, xd2, yd2 = d\n",
    "    dx = max(0, min(xp2, xd2) - max(xp1, xd1))\n",
    "    dy = max(0, min(yp2, yd2) - max(yp1, yd1))\n",
    "    opa = dx * dy\n",
    "    area = (xp2 - xp1) * (yp2 - yp1)\n",
    "    return opa / area\n",
    "\n",
    "assert abs(ratio_overlap_parking_area((0, 2, 5, 4), (2, 1, 4, 5)) - 0.4) < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "economic-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_processing(frame, grid, model, t=0.33):\n",
    "    '''\n",
    "    Estimating load of parking on the frame\n",
    "    \n",
    "    frame: Numpy array; Picture of parking area\n",
    "    grid: Numpy array; Coordinates of all parking spots\n",
    "    model: torch.nn.Module; Model for object detection task\n",
    "    t: float; threshold \n",
    "    '''\n",
    "    results = model(frame)\n",
    "    d_coords = results.pred[0].numpy()[:, :4].astype(np.int32)\n",
    "    is_available = [True] * len(grid)\n",
    "    for i, p in enumerate(grid):\n",
    "        for d in d_coords:\n",
    "            r = ratio_overlap_parking_area(p, d)\n",
    "            if r > t:\n",
    "                is_available[i] = False\n",
    "                continue\n",
    "    return is_available, d_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "governing-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_processing(source, grid, model, t=0.33):\n",
    "    '''\n",
    "    Estimating load of parking on the video stream\n",
    "    \n",
    "    source: cv2.VideoCapture object; videostream from parking area\n",
    "    grid: Numpy array; Coordinates of all parking spots\n",
    "    model: torch.nn.Module; Model for object detection task\n",
    "    t: float; threshold\n",
    "    '''\n",
    "    vrf = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    vr = cv2.VideoWriter('result-full.mp4', vrf, 30.0, (720, 1280))\n",
    "    while source.isOpened():\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = source.read()\n",
    "        if ret == True:\n",
    "            available_spots, d_coords = frame_processing(frame, grid, model, t)\n",
    "            img = frame.copy()\n",
    "            for p, a in zip(grid, available_spots):\n",
    "                x1, y1, x2, y2 = p\n",
    "                color = (0, 255, 0) if a else (0, 0, 255)\n",
    "                img = cv2.rectangle(img, (x1, y1), (x2, y2), color=color, thickness=2)\n",
    "            vr.write(img)\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "gross-commitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/aleksandr/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-9-22 Python-3.8.3 torch-1.12.1+cu113 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 46s, sys: 324 ms, total: 4min 47s\n",
      "Wall time: 47.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5n', device='cpu')  # or yolov5n - yolov5x6, custom\n",
    "# Classes for vehicles:\n",
    "# car: 2\n",
    "# motorcycle: 3\n",
    "# bus: 5\n",
    "# truck: 7\n",
    "# model.classes = [2, 3, 5, 7]\n",
    "\n",
    "grid = []\n",
    "with open('grid.csv', 'r') as f:\n",
    "    for line in f:\n",
    "        grid.append(list(map(int, line.strip().split('\\t'))))\n",
    "grid = np.array(grid)\n",
    "\n",
    "source = cv2.VideoCapture('trehgorka.mp4')\n",
    "\n",
    "video_processing(source, grid, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO size   time\n",
    "# n           47.3s\n",
    "# s           1min 43s\n",
    "# m           3min 11s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
